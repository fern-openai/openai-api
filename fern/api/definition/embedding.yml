# yaml-language-server: $schema=https://raw.githubusercontent.com/fern-api/fern/main/fern.schema.dev.json

service:
  auth: true
  base-path: /embeddings
  endpoints:
    create:
      path: ""
      method: POST
      docs: Creates an embedding vector representing the input text.
      request:
        name: CreateEmbeddingRequest
        body:
          properties:
            model:
              docs: >-
                ID of the model to use. You can use the [List
                models](https://platform.openai.com/docs/api-reference/models/list) API to see all of your
                available models, or see our [Model overview](https://platform.openai.com/docs/models/overview)
                for descriptions of them.
              type: string
            input:
              docs: |
                Input text to get embeddings for, encoded as a string or array of tokens. To get embeddings for multiple inputs in a single request, pass an array of strings or array of token arrays. Each input must not exceed 8192 tokens in length.
              type: EmbeddingInput
            user:
              docs: >
                A unique identifier representing your end-user, which can help OpenAI
                to monitor and detect abuse. [Learn
                more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).
              type: optional<string>
      response: CreateEmbeddingResponse

types:
  EmbeddingInput:
    docs: |
      Input text to get embeddings for, encoded as a string or array of tokens. To get embeddings for multiple inputs in a single request, pass an array of strings or array of token arrays. Each input must not exceed 8192 tokens in length.
    discriminated: false
    union:
      - string
      - list<string>
      - list<integer>
      - list<list<integer>>

  CreateEmbeddingResponse:
    properties:
      object: string
      model: string
      data: list<EmbedData>
      usage: EmbedUsage

  EmbedData:
    properties:
      index: integer
      object: string
      embedding: list<double>

  EmbedUsage:
    properties:
      prompt_tokens: integer
      total_tokens: integer
